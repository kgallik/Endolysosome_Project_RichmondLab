{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699c5ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \twin32 \n",
      "python version: \t3.10.16 \n",
      "torch version:  \t2.8.0+cu126! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bioio import BioImage\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import skimage as sk\n",
    "import napari\n",
    "from cellpose import models, core, io, plot\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2783602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '../WT_RAB5GFP_RAB7mCH/WT_RAB5GFP_RAB7mCH_Image_5_Airyscan_Processing.czi'\n",
    "czi_file = BioImage(test_file)\n",
    "img = czi_file.data\n",
    "img = np.squeeze(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de2b092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 71, 1000, 1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79618304",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1_img = np.squeeze(ch1_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d24e856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kristin.Gallik\\AppData\\Local\\Temp\\ipykernel_5948\\1044138916.py:1: FutureWarning: `napari.view_image` is deprecated and will be removed in napari 0.7.0.\n",
      "Use `viewer = napari.Viewer(); viewer.add_image(...)` instead.\n",
      "  viewer = napari.view_image(img, scale=[czi_file.physical_pixel_sizes.Z,czi_file.physical_pixel_sizes.X,czi_file.physical_pixel_sizes.Y])\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.view_image(img, scale=[czi_file.physical_pixel_sizes.Z,czi_file.physical_pixel_sizes.X,czi_file.physical_pixel_sizes.Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4632a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "if core.use_gpu()==False:\n",
    "  raise ImportError(\"No GPU access, change your runtime\")\n",
    "\n",
    "model = models.CellposeModel(gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719fae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16 11:41:40,924 [INFO] WRITING LOG OUTPUT TO C:\\Users\\Kristin.Gallik\\.cellpose\\run.log\n",
      "2025-08-16 11:41:40,926 [INFO] \n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \twin32 \n",
      "python version: \t3.10.16 \n",
      "torch version:  \t2.8.0+cu126\n",
      "2025-08-16 11:41:42,993 [INFO] running YX: 71 planes of size (1000, 1000)\n",
      "2025-08-16 11:41:42,999 [INFO] 0%|          | 0/71 [00:00<?, ?it/s]\n",
      "2025-08-16 11:44:52,411 [INFO] 1%|1         | 1/71 [03:09<3:40:58, 189.41s/it]\n",
      "2025-08-16 11:48:07,363 [INFO] 3%|2         | 2/71 [06:24<3:41:34, 192.67s/it]\n",
      "2025-08-16 11:51:07,499 [INFO] 4%|4         | 3/71 [09:24<3:31:52, 186.95s/it]\n",
      "2025-08-16 11:52:06,091 [INFO] 4%|4         | 3/71 [10:23<3:55:23, 207.70s/it]\n"
     ]
    }
   ],
   "source": [
    "first_channel = 0\n",
    "second_channel = 1\n",
    "selected_channels = []\n",
    "for i, c in enumerate([first_channel, second_channel]):\n",
    "  if c == 'None':\n",
    "    continue\n",
    "  if int(c) > img.shape[0]:\n",
    "    assert False, 'invalid channel index, must have index greater or equal to the number of channels'\n",
    "  if c != 'None':\n",
    "    selected_channels.append(int(c))\n",
    "\n",
    "\n",
    "\n",
    "img_selected_channels = np.zeros_like(img)\n",
    "img_selected_channels[:, :, :len(selected_channels)] = img[:, :, selected_channels]\n",
    "\n",
    "io.logger_setup()\n",
    "flow_threshold = 0.4\n",
    "cellprob_threshold = 0.0\n",
    "tile_norm_blocksize = 0\n",
    "\n",
    "masks, flows, styles = model.eval(img_selected_channels, channel_axis=0, z_axis=1, batch_size=32, flow_threshold=flow_threshold, cellprob_threshold=cellprob_threshold,\n",
    "                                  normalize={\"tile_norm_blocksize\": tile_norm_blocksize},do_3D=True)\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "plot.show_segmentation(fig, img_selected_channels, masks, flows[0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellPoseCLE-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
